Implementing a Resumable File Uploader (React Uppy + Django-Tus) for OMERO Importer
Overview of Uploader Integration
We plan to integrate a React + Uppy front-end file uploader with a Django + django-tus back-end to enable direct file uploads into OMERO. This will provide a modern, user-friendly interface for importing images, supporting resumable uploads (via the open TUS protocol) and batch selection of multiple files. The uploaded files will be stored on local disk (server-side) in a temporary location and then imported into the target OMERO dataset. Key features include drag-and-drop file selection, upload progress indication, and the ability to resume interrupted uploads[1][2]. We will not support folder uploads initially (only individual files or multi-file selection, not entire directories). The uploader will also implement session persistence so that if a user’s browser crashes or is closed, they can continue the upload when they return[3]. Additionally, we will incorporate event logging for Metabase or other analytics to track usage (e.g. number of files uploaded, upload sizes/durations) for monitoring purposes.
Administrators will have control to toggle this new uploader on or off via the admin panel. If the uploader feature is enabled, the OMERO web client will use the new Uppy-based uploader in place of the existing “in-place” file importer; if disabled, the application will fall back to the original file browser importer interface. This toggle ensures a smooth rollout and the ability to revert to the old importer if needed.
Preliminary Codebase Exploration
Before writing any code, the engineer should examine the current codebase to identify all points of integration for the importer functionality:
•	Front-End (React): Locate the importerApp component (and any related components) responsible for the current import workflow. Identify where the existing file selection UI (the “local FileBrowser”) is implemented. This could involve searching for references to the file browser component or upload dialogs in the React code. Understanding the structure and state management here is crucial, as the new Uppy uploader will need to integrate seamlessly in this flow. Pay attention to how a user selects a target dataset in the UI (likely there is a dropdown or tree view for OMERO datasets) – the new uploader must work with that selection mechanism.
•	Back-End (Django): Open and read through importer_views.py to understand how the current import process is handled. In particular, note the function import_selected (or similarly named) which likely orchestrates taking selected file paths and initiating the OMERO import. We will need to reuse or call this function once new uploads complete, to trigger the same downstream logic. Also inspect how the existing in-place importer works: for example, does it expect file paths as input, or use an OMERO CLI/API call under the hood? Knowing this will help in passing the newly uploaded file to the import logic correctly.
•	Admin Panel Config: Determine how feature flags or configuration options are defined. If the project has a model or settings for toggling features (for instance, some SiteConfiguration or a Django setting that’s exposed in admin), we should use a similar pattern for the “use new uploader” toggle. Check test_admin_views.py for any existing tests of admin settings to understand expected conventions. We will likely create a boolean field (e.g. USE_UPPY_UPLOADER) either in a Django settings file or in a database-backed config model, and expose it in the admin UI. The codebase exploration should reveal where such config might live (possibly in an admin.py or a models.py related to configuration).
•	Conventions & Style: As you explore, note the project’s coding style and conventions. For front-end, observe how components are styled (CSS or semantic UI frameworks) so that the Uppy uploader’s UI can be styled consistently with the rest of the app. For back-end, note how views are structured (function-based vs class-based views, use of Django Rest Framework or plain Django views, etc.) and follow similar patterns. Maintaining consistency will make the new code more maintainable and in line with the existing codebase.
This exploratory step ensures that integration points are well understood before introducing new components. It will help in planning the changes with minimal surprise and aligning the new functionality with existing architecture.
Front-End Integration with Uppy
On the front-end, we will embed the Uppy file uploader into the importerApp React component, replacing the current file browser interface when the feature toggle is ON. Uppy is a highly modular JavaScript uploader that provides an intuitive UI and supports drag-and-drop, multiple file selection, and resumable uploads[2]. We will use Uppy’s Dashboard interface in inline mode so that it appears as part of our page (not a modal).
Uppy Setup in React: We will add Uppy via npm (e.g. @uppy/core and @uppy/dashboard packages) and initialize it within our React component. Uppy offers official React integration (including hooks and components for the Dashboard) for seamless use in React apps[4]. We can either use the React component <Dashboard> or call uppy.use(Dashboard, { inline: true, target: '#selector' }) to mount it in a specific DOM node of our component. The Dashboard provides the file picking area (with drag-and-drop and file dialog support) and shows a list of selected files along with upload progress bars.
By default, Uppy’s Dashboard supports batch file selection – users can select or drop multiple files at once. We will ensure that this remains enabled (no explicit limit on number of files, unless we want to impose one for performance or server limits). We will not enable any folder-dropping plugin, so if a user tries to drag a directory, it will be ignored (only files will be processed). This satisfies the “no folders for now” requirement.
Resumable Upload via Tus: To achieve resumable uploads, we will configure Uppy to use the Tus protocol. Uppy has a built-in Tus plugin (@uppy/tus) that works with any Tus-compliant server[1]. We will initialize Uppy with the Tus plugin pointing to our Django endpoint (e.g. uppy.use(Tus, { endpoint: '/upload/' })). The Tus plugin will handle breaking the file into chunks and sending them via PATCH requests to the server, allowing uploads to resume if interrupted[5][6]. On the first upload attempt, the client sends a POST to /upload/ to create an upload resource, and then uses the returned URL (e.g. /upload/<uuid>) for chunked uploads[7]. This is handled internally by Uppy’s tus-js-client integration. We should confirm the exact endpoint URL in our Django config (likely /upload/ as base, plus /upload/<uuid> for chunks as per django-tus defaults).
Session Persistence: In addition to Tus’s resumability, we will enable Uppy’s Golden Retriever plugin for client-side persistence. Golden Retriever saves the selected files and upload progress in the browser (using localStorage and IndexedDB) so that if the user accidentally closes the tab or the browser crashes, the state can be recovered when they return[3]. This plugin will be used to fulfill the “session tracking: yes” requirement. It ensures that even if the web session is interrupted, users do not have to re-select files and can continue the uploads seamlessly. We simply call uppy.use(GoldenRetriever) during Uppy initialization to activate this feature. (Note: We might also need to register a service worker as per Uppy docs if we want to handle very large files beyond IndexedDB limits, but initially, core GoldenRetriever functionality should suffice.)
Target Dataset Selection: The UI must let users choose an OMERO target dataset before uploading, since the import needs to know where to place the images. The existing importerApp likely already presents a dataset picker (perhaps a dropdown or tree of the user’s datasets). We will preserve that. The uploader interface will be shown in context after a dataset is chosen, or we will require the user to pick a dataset first. We must then ensure the chosen dataset ID is communicated to the back-end import logic. This can be done in a couple of ways: - We could include the dataset ID in the upload metadata. The Tus protocol allows sending metadata with the initial POST (filename, etc.). If django-tus supports reading extra metadata, we might embed the dataset ID there. - Simpler: once the files are uploaded (or as each file finishes), we call a separate API endpoint (or use an existing view) to trigger the import, including the dataset ID and file information. This approach decouples the file transfer from the import action.
For the UI flow, we will likely have an “Upload” button or the act of adding files and starting upload will implicitly trigger uploads. We should guide the user: e.g. 1) select dataset, 2) choose files via Uppy, 3) click “Upload” to start, and then let uploads proceed with progress shown. After uploads complete, we either automatically start the import or inform the user that import is in progress.
Handling Upload Completion: Uppy allows us to listen for events such as upload-success (each file) and a global complete event when all files have finished uploading[8]. We will leverage these events. For each successfully uploaded file, we can invoke the import logic (e.g., call a backend endpoint to import that file into the selected dataset). If multiple files are uploaded, we may call the import for each file as it finishes, or batch them if the import API allows batch processing. The immediate trigger ensures that as soon as a file is on disk, we begin processing it into OMERO.
User Feedback: The front-end should give clear feedback. Uppy’s Dashboard shows progress bars and success/error states for each file. We might also display a message like “Upload complete, starting import…” when an upload finishes and import begins. If import occurs quickly, the user might directly see the new images appear in the UI (if the app updates the dataset view). If import takes longer, we might show a spinner or notification until it’s done. This is an area to consider for good UX, possibly by polling the import status or leveraging OMERO’s notifications if available.
Throughout the front-end integration, we will ensure the new UI matches the existing styling. Uppy Dashboard is fairly self-contained, but we can customize its appearance (CSS) to fit our app’s look and feel. For example, if the app uses a particular color scheme or button style, we can override Uppy’s CSS or provide custom locale strings to match terminology. We’ll also ensure all text (like button labels or messages) are internationalized if the rest of the app is.
Back-End Integration with Django-Tus
On the back-end, we will use the django-tus library to handle the upload protocol. The django-tus app implements the server-side of the TUS 1.0.0 protocol for Django, making it straightforward to accept resumable uploads[9]. Key steps for integration:
1. Install and Configure django-tus: We will add django_tus to our Python dependencies and include it in INSTALLED_APPS in Django settings[10]. Next, we’ll add URL routes for the tus endpoints. Django-tus provides a view called TusUpload which we can plug into our URLconf. According to the documentation, we add two URL patterns: one for the base upload endpoint and one for chunked uploads, for example:
path('upload/', TusUpload.as_view(), name='tus_upload'),
path('upload/<uuid:resource_id>', TusUpload.as_view(), name='tus_upload_chunks'),
These endpoints (as shown above) correspond to initiating an upload and uploading chunks to a given resource ID[7]. We’ll place these under our importer or API URLs as appropriate. The Uppy front-end will POST to /upload/ to create an upload resource and then use the returned <uuid> URL to PATCH the file data.
In Django settings, we need to specify where files go. We’ll configure: - TUS_UPLOAD_DIR: a temporary directory where incoming upload chunks are stored (this can be somewhere like <project>/tus_upload or another temp path)[11]. - TUS_DESTINATION_DIR: a final directory where completed uploads are moved once the upload is finished[11]. We will likely set this to the location OMERO expects imports from (for example, an OMERO import staging area or just a known media folder). In the example config, they used a media/uploads directory[12]. We should ensure the OMERO import process can read from this location. - TUS_FILE_NAME_FORMAT: how to name files to avoid collisions. We can use 'increment' as in the example (which will append a number if a file name already exists)[13], or 'unique' to always generate a unique name. We want to avoid accidental overwrites, so 'increment' or 'random-suffix' might be safest. - TUS_EXISTING_FILE: what to do if a file with the same name exists. The example uses 'error'[14] (fail if exists), but depending on requirements we might choose 'rename' or 'overwrite'. 'error' is safe to prevent unintended overrides – the uploader can inform user if the file name is taken. - We also must ensure Django’s upload size settings accommodate tus chunks. For instance, DATA_UPLOAD_MAX_MEMORY_SIZE should be larger than the chunk size used by the client[15]. If we use the default (which might be a few MB), we should set this accordingly (the example uses 5MB).
After configuring these, starting the Django server will effectively launch a TUS upload endpoint that Uppy can communicate with. Django-tus will handle the low-level details: receiving chunked PATCH requests, storing them in TUS_UPLOAD_DIR, and when complete, moving the file to TUS_DESTINATION_DIR.
2. Triggering OMERO Import After Upload: Once a file upload is complete (fully assembled in the destination directory), we need to initiate the OMERO import for that file. This is the critical glue between django-tus and our existing importer logic. There are a couple of ways to achieve this:
•	Front-end Trigger: As discussed, the front-end can call an API when it gets an upload completion event. We can create a new API endpoint (or reuse the existing import_selected view) that accepts a filename (or file ID) and a target dataset ID, and then calls the underlying import routine. For example, Uppy’s upload-success event gives us the file object and response; from the response or the file metadata we can get the file name or an identifier, then POST to an endpoint like /import_file/ with { filename: "...", dataset: <ID> }. The back-end view would find the file in the upload directory (or directly use the path given by django-tus) and call import_selected(request, dataset_id, filepath) internally. This approach cleanly separates concerns: the tus endpoint purely handles file saving, and our import view handles OMERO integration.
•	Server-Side Hook: Alternatively, we can try to hook directly into the django-tus upload completion. If django-tus has a signal or callback when an upload finishes, we could catch that on the server and immediately call import_selected. Some TUS server implementations provide events (e.g., in .NET one can use an OnFileComplete event[16] to process the file once uploaded). The django-tus documentation doesn’t advertise signals, but we could subclass or wrap the TusUpload view. For instance, we might create our own view that inherits from django_tus.views.TusUpload and override a method (perhaps the post or handle method) to detect when a file is completed. However, implementing this reliably might be complex if not directly supported. It may be easier and more explicit to use the front-end trigger approach above, which is straightforward and testable.
Considering clarity and testability, we will likely implement an explicit import trigger endpoint. This new view (in importer_views.py) could be something like def import_uploaded_file(request): that expects a POST with a file name or ID and dataset ID. It will look up the file in TUS_DESTINATION_DIR (since django-tus would have placed it there upon completion) and then call the existing import_selected logic to actually import the file into OMERO. The import_selected function probably handles moving the file into OMERO’s managed repository and creating the database records for the image. We need to ensure we pass the correct parameters to it (it might accept a list of files or a directory). If import_selected was originally used for selecting files already on disk (from the old file browser), it may accept a path or list of paths – we can reuse that interface.
3. Ensuring Permissions and Cleanup: The import should run as the same user who initiated it (to keep OMERO permissions correct). Since this is within a web session, the import_selected likely already uses the request user’s context. We will double-check that. Also, once imported, we might want to clean up the uploaded file from the temp directory if it’s no longer needed (to save space). Depending on OMERO’s import mechanism, it might move or copy the file. If it copies, we should delete the temp file after a successful import. This cleanup can be done in the import view or in a post-import signal.
4. Back-End Tests: We will write tests in test_importer_views.py to cover the new upload and import process. Possible tests include: - Simulating an upload (perhaps by calling the tus endpoints with a small file) and then calling the import trigger view, asserting that import_selected was called and the file ended up in OMERO. (We might need to mock import_selected or OMERO interactions for a unit test.) - Testing the import trigger endpoint with various scenarios: valid file, non-existent file (should handle gracefully), user without permission to dataset (should be forbidden). - Ensuring that if the uploader is disabled in admin, the upload endpoint might reject requests or the front-end wouldn’t use it (depending on how we implement the toggle).
We will also add tests to test_admin_views.py for the new admin toggle: - Verify that an admin can enable/disable the uploader flag in the admin interface. - Verify that the flag’s state is respected in the application (possibly by checking that the context or configuration passed to the front-end reflects it). For example, if the flag is off, the front-end might not render the Uppy component at all.
Admin Panel Toggle and Configuration
To allow admins to choose between the new uploader and the existing importer, we will introduce a configuration flag accessible via the Django admin. There are a few implementation options: - A simple approach is to add a setting in settings.py (like USE_UPPY_UPLOADER = True/False), but changing that would require a deploy or config change, not ideal for runtime toggling. - Instead, we’ll likely create a model (if one doesn’t exist) to store site-wide configuration. For instance, a model ImporterConfig with a Boolean field use_uploader. We can register this model in admin.py so that site admins can edit it through the Django admin UI. If the project already has a config model, we will extend it. - In the front-end, we need to know whether to show Uppy or the old importer. If the app renders pages via Django templates, we can pass the flag in the context. For example, the view that serves the importer page can include a context variable use_uploader which the React app (if server-side rendered) can pick up. If it’s a single-page app, we might expose an API endpoint for config, or embed the flag in a JSON configuration that the frontend can read on load. - The backend (importer views) may also check this flag. For instance, if someone tries to access the old importer view while the new one is enabled, it might redirect them, or vice versa. Mostly, the toggle will affect the UI and which endpoints are used: when off, the front-end would use the old import mechanism (perhaps selecting a path and calling a different view); when on, it uses the tus endpoints and new workflow.
We will implement the logic such that: - When Uploader is Enabled: The importer page initializes Uppy and uses the /upload/ endpoint. The old file browser component is hidden or removed. The admin setting might also enable the URL patterns for tus (though those can be always enabled; it’s the UI that drives usage). - When Uploader is Disabled: The front-end shows the original file browser (for in-place imports) and does not load Uppy. The tus endpoints could either be inactive or simply not used. We could programmatically include/exclude the URL patterns based on the setting, but that might not be necessary if not used by UI.
In test_admin_views.py, we’ll add assertions to ensure that toggling this flag actually switches the behavior. This could be done by checking the rendered page or an API: for instance, when the flag is on, a GET to the importer page might include indicators of the Uppy widget (or an API call returns a field). We might also simulate an admin changing the setting and ensure no errors occur.
Finally, we will update documentation (if any) to inform admins about this new setting: explaining that they can enable the new uploader for a better user experience (resumable uploads, etc.), and disable if any issues arise or if they prefer the old workflow.
Additional Considerations
•	Metabase/Analytics: We will integrate logging to capture key events for analytics. For example, each completed file import could emit a log entry or an analytic event (containing user ID, dataset ID, file name, size, duration of upload). If a Metabase or similar BI tool is connected to our database, we might store these events in a table that Metabase can query. This will help in monitoring usage of the uploader (how many users use it, success/failure rates, performance of uploads, etc.). Ensuring that we do not log sensitive information is important – mostly aggregate data or non-sensitive metadata should be logged.
•	Performance and Parallel Uploads: The Tus protocol and Uppy support parallel chunk uploads for a single file and simultaneous uploads of multiple files. However, because Django by default is synchronous (unless using async views or a worker system), we might limit parallelism to avoid straining the server. Uppy’s Tus plugin by default will send chunks sequentially unless configured for parallel uploads. We will likely keep the default (sequential) for reliability[17]. For multiple files, Django can handle concurrent requests, but if the server resources are limited, we might want to limit how many files a user can upload at once. This can be done via Uppy’s restrictions (e.g. max number of files, or uploading one by one). Initially, we assume moderate usage, but this can be revisited if performance issues arise.
•	Error Handling: We need to handle errors gracefully. If an upload fails (network issue, server error), Uppy will report it and can retry. We should configure reasonable retry logic or at least inform the user to retry. If the import fails (e.g., OMERO rejects the file format or there’s a server-side error), we should catch that in import_selected and report back to the user. Possibly, the import trigger view can return a status that the front-end can display (“Import failed for File X”). User feedback is key, so we’ll implement messaging for success and failure cases.
•	Security: Ensure that the upload endpoint is protected – only authenticated users can upload, and they can only import to datasets they have access to. Django-tus’s view might need to be wrapped or configured to require login. We can put the tus URLs behind our existing authentication (if using Django sessions or tokens). Also, validate the files – since we allow direct upload, we might want to restrict types or sizes at the application level (though OMERO will also validate image files). Uppy can enforce file type and size limits on the client side[18], which we can set (for example, allow only image MIME types if appropriate, and perhaps a max size per file to what OMERO can handle). These checks improve security and user experience by preventing obviously disallowed files from ever uploading.
•	Maintainability: Follow the project’s coding standards. Add comments where non-obvious, especially around the integration points (to explain why we call import here, etc.). Future developers should be able to understand the flow: from user selecting files -> uploading via Uppy/Tus -> file saved on server -> import triggered -> OMERO dataset updated.
By carefully implementing the above and writing comprehensive tests, we will deliver a robust uploader feature. The result will be a much improved import experience in OMERO.web: users can upload images straight from their machine with drag-and-drop ease, enjoy resumable transfers for large files, and admins retain control to switch back if needed. This aligns with modern web app capabilities and addresses the previous limitations of the in-place importer.
Sources:
•	Uppy file uploader official docs and features[2][4]
•	Transloadit (Uppy) blog – on Uppy events and upload success handling[19]
•	Uppy Tus plugin documentation – resumable uploads via Tus protocol[1][20]
•	django-tus setup example – adding URL patterns and settings for upload directories[7][12]
•	SCSS Consulting blog – using Tus in Django, benefits of resumable uploads[5][15]
•	Uppy Golden Retriever documentation – restoring uploads after crashes[3]
________________________________________
[1] [6] [20] Tus | Uppy
https://uppy.io/docs/tus/
[2] [4] [8] [18] [19] Crafting a seamless upload experience with Uppy | Transloadit
https://transloadit.com/devtips/crafting-a-seamless-upload-experience-with-uppy-and-xhr/
[3] Golden Retriever | Uppy
https://uppy.io/docs/golden-retriever/
[5] [7] [10] [11] [12] [13] [14] [15] [17] Resumable Uploads In Django With TUS: Rethinking File Uploads
https://scssconsulting.com.au/resumable-uploads-in-django-with-tus-rethinking-file-uploads/
[9] Implementations | tus.io
https://tus.io/implementations
[16] Processing a file once the file upload is complete · tusdotnet/tusdotnet Wiki · GitHub
https://github.com/tusdotnet/tusdotnet/wiki/Processing-a-file-once-the-file-upload-is-complete
